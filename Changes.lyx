#LyX 2.2 created this file. For more info see http://www.lyx.org/
\lyxformat 508
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts true
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
A Transient Renderer based on Pbrt
\end_layout

\begin_layout Section
Base
\end_layout

\begin_layout Standard
All modifications are based on the 
\family typewriter
master
\family default
 (which includes changes not found in the 
\family typewriter
book
\family default
 branch
\family typewriter
)
\family default
branch of the official pbrt3 repository.
 Changes from the 
\family typewriter
master
\family default
 branch are to be regularly checked into the transient rendering branch,
 thus it should always be based on the most up to date version.
\end_layout

\begin_layout Section
New Concepts
\end_layout

\begin_layout Subsection
Sample sum normalization
\end_layout

\begin_layout Standard
The sum of sample values is normalized to account for different amounts
 of samples (i.e.
 if the scene is rendered with 4 times as many samples, it should have the
 same brightness (but less noise)).
 It is not sufficient, to just divide by a static number of samples, as
 different pixels have a different sampling density due to filtering.
 Edge pixels won't get any contribution from pixels outside the image and
 by randomizing the ray origin and direction, the density varies slightly
 in general.
 Thus in pbrt, each pixel sums up the filter weights and the pixel value
 is divided by this number in the end.
\end_layout

\begin_layout Standard
In our case, we cannot sample the time dimension explicitly.
 This means, that we do have a importance sampling in the time domain (but
 not in the spatial dimensions), and more samples mean more light.
 Thus, the correct solution is to store the weights not per transient pixel,
 but per 
\begin_inset Quotes eld
\end_inset

spatial
\begin_inset Quotes erd
\end_inset

 pixel, i.e.
 one weight value for each x,y coordinate.
 Every time bin of a single spatial pixel is then divided by the same accumulate
d weight for this pixel.
\end_layout

\begin_layout Standard
Additionally, every sample is divided by the temporal bin size.
 The transient image is a distribution of light per time, and thus must
 be integrated to retrieve the absolute amount of light for a time interval.
 The compute the absolute intensity of a spatial pixel, the bin values can
 be thought of as Monte Carlo samples, thus adding them, dividing them by
 their count and multiplying by the interval length will yield the integral
 value.
\end_layout

\begin_layout Subsection
Filtering in the transient dimension
\end_layout

\begin_layout Standard
Just as in the two spatial dimensions wee need filtering in the spatial
 dimension to avoid implicit box filtering.
 The same principles apply as in spatial filtering.
 As simplification, we use the filter table that is already stored for spatial
 filtering.
 In the future it might be possible to specify a different filter or filter
 size for the temporal dimension, but for now using the same values is fine.
\end_layout

\begin_layout Standard
With temporal filtering, weighting gets slightly more complicated.
 In theory, a single sample is just distributed over multiple time bins.
 Due to clamping (and possibly other effects) it is however not guaranteed,
 that these temporal filter weights add up to 1.
 Additionally we use just one row of a 2d filter and then assume, that the
 filter is separable (as all standard filters in pbrt are).
 This means, that we compute the sum of the weights of the temporal filter
 and divide by it later to ensure that the total intensity remains unchanged
 by the filtering.
\end_layout

\begin_layout Subsection
blub
\end_layout

\begin_layout Standard
In practice, multiple samples are generated for each pixel.
 Because of different filters and positional offsets, each sample has a
 weight that is then used to compute the intensity value.
 As we cannot directly sample the geometric path length (it is a result
 of our sampling), 
\end_layout

\begin_layout Section
Transient Images
\end_layout

\begin_layout Subsection
Transient Image definition
\end_layout

\begin_layout Standard
Transient images are time resolved intensity images.
 Thus, appropriate integrating over the time dimension yields an intensity
 image of the scene.
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $I$
\end_inset

 bet the 
\emph on
intensity image
\emph default
, that stores an intensity 
\begin_inset Formula $v$
\end_inset

 per discrete pixel
\begin_inset Formula 
\[
I\left(x_{i},y_{j}\right)=v_{i,j}
\]

\end_inset

By adding a continuous temporal axis to the image, we get the 
\emph on
continuous transient image
\emph default
 
\begin_inset Formula $T_{c}$
\end_inset

 which describes the temporal response of each pixel.
 Integrating along the temporal axis yields the intensity image:
\begin_inset Formula 
\[
\int_{t}T_{c}\left(x_{i},y_{j},t'\right)\,\text{d}t'=I\left(x_{i},y_{i}\right)
\]

\end_inset


\end_layout

\begin_layout Standard
When discretizing 
\begin_inset Formula $T_{c}$
\end_inset

 in the temporal dimension (so that we can store it), we could come up with
 the following solution:
\begin_inset Formula 
\[
I\left(x_{i},y_{j}\right)=\sum_{t\in\left[t_{o}\ldots t_{n-1}\right]}T_{s}\left(x_{i},y_{j}t\right)
\]

\end_inset

However in this formulation, the values of 
\begin_inset Formula $T_{s}$
\end_inset

 change when the discretization is changed (e.g.
 twice as many bins with half width).
 If we interpret the temporal dimension as a density, we have (for equidistant
 bins) the following formula:
\begin_inset Formula 
\[
I\left(x_{i},y_{j}\right)=\frac{t_{n-1}-t_{0}}{n}\cdot\sum_{t\in\left[t_{o}\ldots t_{n-1}\right]}T_{d}\left(x_{i},y_{j}t\right)
\]

\end_inset

where 
\begin_inset Formula $\frac{t_{n-1}-t_{0}}{n}$
\end_inset

 is the width of a single bin (in seconds).
 Thus the unit of 
\begin_inset Formula $T_{d}$
\end_inset

 is intensity per second, i.e.
 the power.
 The question is now, how can 
\begin_inset Formula $T_{d}$
\end_inset

 be computed using path tracing?
\end_layout

\begin_layout Subsection
Monte Carlo Integration
\end_layout

\begin_layout Standard
Each pixel of 
\begin_inset Formula $I$
\end_inset

 is computed using Monte Carlo integration.
 Each sample is a (very rough) approximation of the real value.
 By computing many of them and computing the average this real value can
 be approximated with high precision.
\end_layout

\begin_layout Standard
The geometric path length cannot be sampled directly.
 If more samples fall in the same temporal bin, this means that more light
 arrived at this time and thus they must be summed and not averaged.
 Averaging is performed per spatial pixel, not per transient pixel.
 If 100 samples are used, every temporal bin is divided by 100 and not by
 the number of samples that actually fell into this particularly bin.
\end_layout

\begin_layout Standard
Before a pixel is written into the bin it must be divided by the bin width.
 Thus 
\begin_inset Formula $T_{d}=\frac{n}{t_{n-1}-t_{0}}\cdot T_{s}$
\end_inset

.
 This means, that 
\begin_inset Formula $T_{d}$
\end_inset

 is (in a certain way) invariant under changes of the temporal discretization.
\end_layout

\begin_layout Section
Modifications
\end_layout

\begin_layout Subsection
Minor modifications
\end_layout

\begin_layout Itemize
some changes to the build system and 
\family typewriter
CMakeLists.txt
\end_layout

\begin_layout Itemize
different startup message
\end_layout

\begin_layout Subsection
Transient Film
\end_layout

\begin_layout Standard
A class to store the transient images.
\end_layout

\begin_layout Subsubsection
Design Choice
\end_layout

\begin_layout Standard
The main challenge is, that pbrt was written with the computation of 2D
 images in mind.
 Thus, there currently is only a single film class (
\family typewriter
Film
\family default
), and its interface heavily assumes 2D images.
 We can't derive from it, as it creates the pixel storage already in the
 ctor and we would end up having two image buffers.
 We can also not create a common base class, because it would still need
 to have the 2D image interface, which is directly used by pretty much everyone.
 A clean way of implementing it would require to categorize the integrators
 somehow in two different types, each using the appropriate type of film.
 However, we want a minimal changes branch from pbrt to make it easier for
 new people to jump in and use it.
\end_layout

\begin_layout Standard
It would be nice, to just ignore the film in the camera class and use or
 own.
 Unfortunately, the film is deeply connected to other parts of pbrt.
 The camera itself and sampler use its properties, so it cannot simply be
 removed.
\end_layout

\begin_layout Standard
So we create a new class, 
\family typewriter
TransientFilm
\family default
.
 The 
\family typewriter
TransientFilm
\family default
 class is implemented analogues to the 
\family typewriter
Film
\family default
 class, however with the required changes in the interface to account for
 transient images.
 
\family typewriter
TransientFilm
\family default
 is not related to 
\family typewriter
Film
\family default
 in any ways (through the usual OOP ways), but just a very similar class.
 For its initialization, the same parameters as the ones for 
\family typewriter
Film
\family default
 are used.
 It is then stored as a member object of 
\family typewriter
TransientPathIntegrator
\family default
 and used inside its 
\family typewriter
Render
\family default
 method.
\end_layout

\begin_layout Standard
The downside is, that we still have the old 
\family typewriter
Film
\family default
 object, which is unused except for its parameters which are used all over
 pbrt.
 However, the frame buffer is not too big and thus the memory waste is negligibl
e.
 It is also nicer, to have all the stuff, that we don't use (the 2D frame
 buffer) in a completely different object, rather than in the same (as would
 happen, if we used it as a base class).
 On the upside, this solution only require minimal changes to pbrt and two
 additional files, which are implemented more or less analogeously to their
 counterparts.
\end_layout

\begin_layout Subsubsection
Differences to TransientFilm
\end_layout

\begin_layout Itemize
pixel data are now 3D (crop window is still 2d though, as we only implicitly
 sample the time dimension)
\end_layout

\begin_layout Itemize
additional temporal filter (maybe the same as the image filter, maybe a
 different one)
\end_layout

\begin_layout Itemize
film tiles are supplied as usual (though they have a new pixel format now,
 obviously)
\end_layout

\begin_layout Itemize

\family typewriter
AddSplat
\family default
 is removed as it is not used by the path tracer (might be used later for
 bidirectional path tracing or so)
\end_layout

\begin_layout Itemize

\family typewriter
WriteImage
\family default
 does so in a transient image format
\end_layout

\begin_layout Itemize
Filtering: additional filter for the temporal dimension.
 For now independent from the image filter
\end_layout

\begin_layout Subsubsection
TransientFilmTile
\end_layout

\begin_layout Standard
has an additional tresolution parameter.
 As time bins are not sampled directly, cropping would not make sense, which
 is why we keep the original 2d pixel bounds.
\end_layout

\begin_layout Subsubsection
API
\end_layout

\begin_layout Standard
The only changes in the API are in the part where the Integrator is created.
 As all TransientFilm parameters are now stored in the TransientPathIntegrator
 properties, the TransientFilm is created in the same block (and before)
 the TransientPathIntegrator.
 Thus, the changes to the API are minimal.
\end_layout

\begin_layout Subsubsection
Integrator support
\end_layout

\begin_layout Standard
By removing the splat- and SetImage functionality, TransientFilm does not
 support some of the advanced integrators.
 Maybe this functionality needs to be readded, if they are to be used in
 the future.
\end_layout

\begin_layout Subsubsection
Unused parameters warning
\end_layout

\begin_layout Standard
pbrt will warn about not using the parameters 
\family typewriter
t_resolution, t_min
\family default
 and 
\family typewriter
t_max
\family default
.
 This is caused by creating the superflous film object (which of course
 does not use these parameters) as described above.
 Fixing this warning would require not creating this object or actively
 suppress the warning.
 The first one is not really possible (see above), the second one would
 require quite a hack that at this point is just not worth it.
\end_layout

\begin_layout Standard
So for now, the warning will stay and can safely be ignored.
 It is ultimately caused by our design descission of not changing the general
 implementation of pbrt in a way that would allow a truely clean implementation
 of our new features.
\end_layout

\begin_layout Subsection
Transient Path
\end_layout

\begin_layout Standard
TransientPathIntegrator is a combination of SamplerIntegrator and PathIntegrator
, but for the transient case.
\end_layout

\begin_layout Standard
At its core, it extends PathIntegrator to also compute the distances of
 the rays.
 However, to increase efficiency, PathIntegrator::Li computes not only the
 light along the complete path, but also computes direct illuminations of
 all sub paths.
 All contributions are added and returned to SamplerIntegrator::Render.
 In our case however, each subpath has a different length, and we need to
 return multiple samples, which is the reason why we also have to change
 the SamplerIntegrator::Render method.
\end_layout

\begin_layout Standard
Apart from the Render method (which we need to change), SamplerIntegrator
 only has some helper functions, that we do not use.
 Hence we combine our changes to PathIntegrator and SamplerIntegrator to
 a single class TransientPathIntegrator.
\end_layout

\begin_layout Itemize
Li does not only return a single intensity, but writes a intensity for each
 path segment (as they can no longer just be added any more)
\end_layout

\begin_layout Itemize

\family typewriter
FilmParameters
\family default
: As this integrator manages its own film (usually, the camera does this),
 it also needs to initialize it.
 Thus, upon creating of the transientPath integrator, all parameters for
 the film are parsed and stored in this very structure, which is later used
 to initialize the filter in the 
\family typewriter
Render
\family default
 method.
\end_layout

\begin_layout Subsubsection
UniformSampleOneLight
\end_layout

\begin_layout Standard
While sampling the light source, the distance from the last point on geometry
 to the light source must be considered.
 For this, 
\family typewriter
UniformSampleOneLight
\family default
 must also return this distance.
 This is implemented by copying 
\family typewriter
UniformSampleOneLight
\family default
 and 
\family typewriter
EstimateDirect
\family default
 into the functions 
\family typewriter
TransientUniformSampleOneLight
\family default
 and 
\family typewriter
TransientEstimateDirect
\family default
.
 In the spirit of minimal changes, this may be a code dubplication but leaves
 the rest of pbrt completely untouched.
 Using an appropriate diff tool it is still possible to see these minimal
 changes and merge changes of the original functions in the transient ones.
\end_layout

\begin_layout Subsection
per-instance Render options
\end_layout

\begin_layout Standard
Monte Carlo integration can use an arbitrary amount of samples.
 This makes an progressive rendering approach tempting, where the scene
 is rendered multiple times with a low amount of samples, and the results
 are stored in different files.
 These files can later be combined to a single image with greatly reduced
 noise.
 This approach makes it possible, to stop the rendering process at any time
 without loosing progress.
\end_layout

\begin_layout Standard
However, in the default settings, pbrt uses the same samples in every run
 and thus the noise patterns don't vary.
 A seed parameter could be added to the file format, but this would require
 changing the input file everytime.
 Instead, we want to pass the seed (and the numbered output filename) as
 command line argument.
\end_layout

\begin_layout Standard
A nice solution would be, to first read all information of the input file
 and then to override some of them with the command line arguments.
 Sadly, this is not how the parsing works in pbrt, and they already use
 global variables to specify the filename (except in the original version,
 the filename in the input file has a higher priority, which feels strange
 given that command line arguments are more volatile - and it is also inconvinie
nt for us).
 So we changed the filename priority.
\end_layout

\begin_layout Standard
Random seeds are a bigger problem, pbrt does not support them on many levels.
 Again, we settled for a solution, that requires little code changes and
 works well, but is rather ugly from a design perspective: The PRNG has
 now a global state, that can be changed on program startup.
 I really hope, that the chosen algorithm does not rely too deeply on the
 default initialization values and that the way we set them don't result
 in terrible random numbers.
\end_layout

\begin_layout Section
Importance Sampling
\end_layout

\begin_layout Standard
Key observation: The scene consists solely of the wall and the object.
 While the object is illuminated by the laser spot, the wall is not.
 The only way, that a ray hitting the wall can contribute any intensity,
 is if it is connected to the object.
 So, from the wall, the object should always sampled next.
 The object however can receive light from the light source, the wall or
 the object itself.
 Thus, the importance sampling strategy on the object is probably fine,
 but the wall should really exclusively sample the object.
 This changes, when a background scene is introduced, but in this case the
 majority of the samples should still be spend on the object.
\end_layout

\begin_layout Subsection
Implementation
\end_layout

\begin_layout Itemize
Blender objects have an additional flag 
\family typewriter
pbrt3_semantic
\end_layout

\begin_layout Itemize

\family typewriter
TriganleMesh
\family default
 has additional 
\family typewriter
ObjectSemantic
\family default
 that is loaded from the scene file
\end_layout

\begin_layout Itemize
upon scene construction, the 
\family typewriter
Primitive
\family default
s list that is used to build the acceleration structures is passed to the
 
\family typewriter
Scene
\family default
 constructor and filtered for 
\family typewriter
NlosObject
\family default
s.
 The results are stored inside 
\family typewriter
Scene::nlosObjects
\family default
 with public access.
\end_layout

\begin_layout Itemize

\family typewriter
TransientPathIntegrator::Li
\family default
 fetches the 
\family typewriter
TriangleMesh
\family default
 from the 
\family typewriter
SurfaceInteraction
\family default
 and checks if that flag is set to 
\family typewriter
NlosReflector
\end_layout

\begin_layout Itemize
ObjectSampling: Starting from the wall, we need to sample NlosObjects.
 Uniform sampling of the hemisphere should lead to the correct result, but
 would be inefficient.
 Directly sampling the surface area of the objects would be extremely efficient,
 but special care must be taken for the normalization.
\end_layout

\begin_deeper
\begin_layout Itemize
pick a random primitive to sample by using a 
\family typewriter
Distribution1D
\family default
 (758)
\end_layout

\begin_layout Itemize
pick a random point on the object
\end_layout

\begin_layout Itemize
create a ray, that goes in this direction and proceed as usual
\end_layout

\end_deeper
\begin_layout Standard
Problems, that need to be adressed:
\end_layout

\begin_layout Itemize
do we sample over angles or area?
\end_layout

\begin_deeper
\begin_layout Itemize
when doing angular sampling: how do we compute the angle region, that we
 want to sample? (how do we compute a bounding sphere around the object
 and sample it?)
\end_layout

\begin_layout Itemize
For area sampling: can we use shape::sampleArea (as with area light sources?)
 this would probably be the most efficient way.
\end_layout

\end_deeper
\begin_layout Itemize
how is the weighting computed?
\end_layout

\begin_layout Subsection
Probabilities
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename ImportanceSampling.svg
	width 80col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset

Special care must be taken to compute the correct probabilities for each
 sampled point.
 Normally, we would want to sample the hemisphere over the point 
\begin_inset Formula $p$
\end_inset

 uniformly.
 Instead, we can sample it non-uniformly, when every sample is weighted
 by the reciprocal of its probability.
\end_layout

\begin_layout Standard
Intuitively, we would try to estimate the direction and size of the object
 and create an angular domain that is then sampled.
 However, fitting the whole contour of the object in a small as possible
 angular interval is difficult.
 Instead, we can sample in the area domain and reweight the samples for
 the angular domain.
\end_layout

\begin_layout Standard
In the figure, two triangles with the same area but different orientations
 are sampled with for rays (green) each.
 It is clearly visible, that the right triangle is sampled more densly in
 the angular domain.
 However, the weighting factor of 
\begin_inset Formula $\frac{\cos\theta}{r^{2}}$
\end_inset

 will compensate the increased density perfectly.
 This distribution is actually something we don't want, instead an importance
 sampling by light intensity would be better.
 This is however still a good sampling distributions as it at least guarantees,
 that each ray hits the object.
\end_layout

\begin_layout Standard
If we sample uniformly in the area domain and apply the weighting factor,
 we are guaranteed to compute the same result as if we would sample uniformly
 in the angular domain.
 The transformation can be done via 
\begin_inset Formula $\frac{\cos\theta}{r^{2}}$
\end_inset

 which means we only need to select points uniformly distributed by area.
 Sampling points on triangles is easy and already implemented.
 The triangles themself must be weighted by their area and selected by an
 arbitrary distribution, or directly sampled according to their sizes.
 As pbrt already divides by the triangle area in the usual sampling function,
 only the first option is viable.
\end_layout

\begin_layout Standard
Lastly, special care must be taking concerning occlusion.
 In the figure, a part of the rightmost triangle is occluded by another
 triangle.
 If point 
\begin_inset Formula $B$
\end_inset

 is sampled, the sample must be completely discarded, as sampling in this
 direction will result in a sampling of point 
\begin_inset Formula $C$
\end_inset

.
 Thus, a part of the occluding triangle would be sampled more often without
 any compensation from an additional weight.
 Thus, the only correct choice is to discard the sample completely.
\end_layout

\begin_layout Standard
Thus, sampling in the area domain is possible, if the points are sampled
 uniformly (with respect to area) and occlusion is minded.
 The resulting distribution in the angular domain will only be close to
 perfect, but still correct.
\end_layout

\begin_layout Subsection
NLoS object selection
\end_layout

\begin_layout Standard
Not all parts of an object are visible from the reflector.
 So we only add those triangles to the list, that are potentially visible.
\end_layout

\begin_layout Standard
All reflector vertices are collected in a set.
 For every object triangle it is checked whether at least one of them is
 in fornt of the plane defined by this triangle.
 In this case, it is potentially visible.
\end_layout

\begin_layout Section
Limitations
\end_layout

\begin_layout Subsection
Spectral rendering
\end_layout

\begin_layout Standard
For now, we do not support spectral rendering, i.e.
 colors.
 It would be cool, to see the dyed reflections from differently colored
 objects appear one after the other and could be helpful for quite some
 visualizations.
 But there is no camera on the market, that could measure those, so it is
 not very useful for synthetic data generation.
\end_layout

\begin_layout Standard
In the future, this could be a cool project.
 But it is really straightforward to implement and would be good for nothing
 but a few plots.
\end_layout

\begin_layout Section
TODO
\end_layout

\begin_layout Subsection
Filtering check
\end_layout

\begin_layout Standard
Make sure, that introducing the temporal filter did not change any intensity
 images.
 Render images with lots of samples with and without filtering and compare
 them.
\end_layout

\begin_layout Subsection
temporal cut of
\end_layout

\begin_layout Standard
What do we do with paths, that are outside our ROI? If we just ignore them,
 they still had a nonzero probability of occuring, thus our overal weight
 might be wrong.
\end_layout

\begin_layout Subsection
NLOS Object sorting
\end_layout

\begin_layout Standard
Triangles that are not visible from the wall (determined by normal vector)
 should not added to the list to improve efficiency.
\end_layout

\begin_layout Subsection
MaxDepth error handling
\end_layout

\begin_layout Standard
For subpaths cache the fixed limit of rays should handled properly.
 Right now it seems, that it just crashed, without showing you the nice
 error message that we wrote.
\end_layout

\begin_layout Subsection
Laser spot
\end_layout

\begin_layout Standard
add option whether or not the laser spot should be visible (enable / disable
 direct emission at the intersection point)
\end_layout

\begin_layout Section
Bugs
\end_layout

\begin_layout Subsection
Intensity drop (solved but not understood)
\end_layout

\begin_layout Standard
For normal sampling, the image sometimes depends on the time interval of
 the output.
 The waves experience a massive intensity drop towards the edges of the
 image which has a circular outline.
 This only happens for the normal sampling.
\end_layout

\begin_layout Standard
The issue was solved (rev 
\family typewriter
4f2c48a6971aff6e9a8e959affcfa11469369aee
\family default
) by accumulating all sub paths into a single pixel so that the total sample
 weight does not depend on the number of subpaths.
 This is analogue to vanilla path tracer, though I'm not completely sure,
 why this is the right way of doing it.
\end_layout

\begin_layout Subsection
Ray length dependencies
\end_layout

\begin_layout Standard
When the maximum path tracing depth is changed, the intensity of the primary
 peak changes slightly.
 Even worse, it increases for fewer samples.
 We would expect to see new higher order bounces and thus a sligth increase
 in the integrated intensity, but certainly not this.
\end_layout

\end_body
\end_document
